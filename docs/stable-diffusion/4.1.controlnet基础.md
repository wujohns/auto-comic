# controlnet 基础
controlnet 本质上是一种类似 lora 的微调模型的方案，由于其在精细化控制上的优异表现，被广泛的应用在ai的精准绘制当中  

当前现状:  
1. 针对绘画场景有多种针对不同任务场景的 controlnet 模型（姿势控制只是其中一种）  
1. 除此之外也有将多个 controlnet 模型组合做综合控制的实现方案（multi-control）  

## 插件安装
需要注意的是:  
1. controlnet 除了插件本身之外还有针对不同任务场景训练的模型  
1. 所以下文中除了插件的地址外，还有各个模型的信息，这些 controlnet 模型作者是直接发布到 huggingface 上的，需要下载到 `stable-diffusion-webui\extensions\sd-webui-controlnet\models` 目录中  
1. 详细可以参考插件的 github readme，里面的说明挺详细的  

插件地址: https://github.com/Mikubill/sd-webui-controlnet.git  

这里仅列举当前要用到的 controlnet 模型:  
地址: https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main  
1. control_v11p_sd15_openpose.pth - 动作姿势控制  
1. control_v11f1p_sd15_depth.pth - 深度(景深)  

1. control_v11p_sd15_canny.pth - 边缘检测(线稿)  
1. control_v11p_sd15_lineart.pth - 线稿(一般用于线稿上色处理)  
1. control_v11p_sd15_softedge.pth - 柔和边缘  
1. control_v11p_sd15_scribble.pth - 涂鸦乱画  

1. control_v11f1e_sd15_tile.pth - 高清放大处理  
1. reference_only - 用于做风格适配（这边测试在人物面部特征风格处理上有较好的效果）  

1. control_v11p_sd15_inpaint.pth - 局部重绘（在一些情形下效果比原始方案更好）  
1. control_v11p_sd15_seg.pth - seg分割  

t2i-adapter 系列的 controlnet 模型地址: https://huggingface.co/TencentARC/T2I-Adapter/tree/main/models  
1. t2iadapter_color_sd14v1 - 将图片的颜色进行分块，作为绘制时的参考  

一些问题:  
1. 安装插件后建议手动重启一下 webui，会安装 controlnet 的 python 依赖  
1. 在初次使用时会遇到下载对应的预处理模型问题，可以查看日志做手动下载处理  
1. 动作姿势控制部分可以配合 openpose-editor 插件实现更精确的控制: https://github.com/huchenlei/sd-webui-openpose-editor  

## 基础使用
![imgs/controlnet-base.png](/imgs/controlnet-base.png)  

## multi-controlnet 配置
在一些场景下需要使用多个 controlnet 做配合，这个时候可以在  
`设置(Settings) -> ControlNet -> Multi ControlNet 的最大网络数量`  
设置最多可以同时使用的 controlnet 数目

## 参考
controlnet相关讲解: https://www.bilibili.com/video/BV1Ds4y1e7ZB  
不同的训练方式: https://zhuanlan.zhihu.com/p/611310582  
