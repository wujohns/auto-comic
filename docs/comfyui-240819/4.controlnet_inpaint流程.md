# controlnet inpaint 流程

## 基于 controlnet++ 的方案
这里使用和 ComfyUI-Advanced-Controlnet 插件兼容的 controlnet 模型  
Controlnet++ 系列模型  
1. 模型地址: https://huggingface.co/xinsir/controlnet-union-sdxl-1.0  
1. 该模型是一个多合一模型(包含多种特性)  
1. 下载 diffusion_pytorch_model_promax.safetensors 这个文件到 `models/controlnet/` 目录  

## 基于 BrushNet 的方案
BrushNet 专注于做重绘方向
1. 节点地址: https://github.com/nullquant/ComfyUI-BrushNet  
1. 模型放置的位置在 models/inpaint 目录下(也可以在 extra_model_paths.yaml 修改 inpaint 变量做重新指定)  
1. models/inpaint 下可以建子目录  
1. 参考该节点工程的 Installation 下的说明操作即可  

## 传统方案
复刻 sd-webui 效果的方案  
1. sdxl 模型 - realDream_sdxlPony10.safetensors  
1. controlnet 模型 - Kataragi_inpaintXL-lora128.safetensors  
1. 依赖节点: https://github.com/Fannovel16/comfyui_controlnet_aux - inpaint 预处理节点  
1. 要点在于使用自定义的包含 mask 的 latent 实现图片的大部分不改动  

## 最终选择
传统方案的跨模型绘制(泛用型)效果最好

## 部分坑
如果 mask 没有生效，可以使用以下节点中的 image2rgb 对 image+mask 的结果做处理  
1. https://github.com/WASasquatch/was-node-suite-comfyui - 用于支持 image2rgb  

## 其他潜在的选项
这个项目中的 inpaint 选项可能会较为不错
1. https://github.com/Acly/comfyui-inpaint-nodes

## 其他情报
可能的 inpaint 相关: https://civitai.com/models/626876/flux-inpainting-img2img-txt2img-controlnet-integration-with-auto-prompt-sdxl-ipadapter-controlnet-upscaler  

https://medium.com/@promptingpixels/inpainting-with-comfyui-basic-workflow-with-controlnet-911428c5c57c

flux 的 inpaint 部分需要新的机器(否则需要消耗太多的时间):
https://www.reddit.com/r/comfyui/comments/1elunbq/workflow_sam2_flux_inpainting_facial_expression/  

参考这个
https://www.bilibili.com/video/BV1yS421X7wa
